import os
import operator
from typing import Annotated, List, TypedDict, Union
import re # Importamos regex para limpieza fina

import chromadb
from sentence_transformers import SentenceTransformer
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langgraph.graph import StateGraph, END

# --- 1. CONFIGURACI√ìN DE INFRAESTRUCTURA ---
CHROMA_HOST = os.getenv("CHROMA_HOST", "localhost")
CHROMA_PORT = 8000

print(f"üîå Conectando a ChromaDB en {CHROMA_HOST}:{CHROMA_PORT}...")

try:
    chroma_client = chromadb.HttpClient(host=CHROMA_HOST, port=CHROMA_PORT)
    collection = chroma_client.get_collection("project_archive")
    print("‚úÖ Conexi√≥n exitosa a la colecci√≥n 'project_archive'")
except Exception as e:
    print(f"‚ö†Ô∏è Advertencia: No se pudo conectar a ChromaDB ({e}). Se usar√° modo mock si falla.")
    collection = None

print("üß† Cargando modelo de embeddings para consultas...")
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash-lite",
    temperature=0.7,
    google_api_key=os.getenv("GOOGLE_API_KEY")
)

# --- 2. PERSONALIDADES ---
AGENTS_CONFIG = {
    "Survivor": {
        "role": "Oficial de Bioseguridad y Supervivencia.",
        "source_filter": "survivor_context",
        "keywords": "covid pandemic virus death emergency quarantine fear symptoms hospital",
        "style": """
        Eres paranoico, met√≥dico y obsesionado con la prevenci√≥n.
        Tu lenguaje es t√©cnico-militar y m√©dico.
        Frases clave: 'Protocolo de contenci√≥n', 'Carga viral', 'Zona cero'.
        Ves peligros en todos lados. Tu tono es de alerta urgente.
        """
    },
    "Speculator": {
        "role": "Analista de Mercados Cuantitativo.",
        "source_filter": "speculator_context",
        "keywords": "stock market finance money spx nasdaq crash volatility profit liquidity",
        "style": """
        Eres un analista fr√≠o, matem√°tico y pragm√°tico. No eres malvado, simplemente indiferente a lo humano.
        Solo te importan los n√∫meros, el ROI y la volatilidad.
        Donde otros ven tragedia, t√∫ ves patrones gr√°ficos y correcciones de mercado.
        Usas jerga financiera t√©cnica: 'Bull trap', 'Liquidez', 'Soporte', 'Volatilidad'.
        Tu tono es seco, directo y desapegado.
        """
    },
    "Auteur": {
        "role": "Director de Videojuegos Visionario (Estilo Hideo Kojima).",
        "source_filter": "auteur_context",
        "keywords": "connection strands isolation technology soul humanity art cinema",
        "style": """
        Eres un creador enigm√°tico que habla mediante aforismos cortos y profundos.
        Hablas con sentencias potentes como en un tr√°iler de cine.
        Hablas de 'conexiones' (strands) y la soledad digital.
        Tu tono es melanc√≥lico pero muy conciso.
        """
    }
}

# --- 3. ESTADO ---
class AgentState(TypedDict):
    question: str
    analysis_logs: Annotated[List[dict], operator.add] 
    final_synthesis: str

# --- 4. FUNCIONES CORE ---

def query_chroma(query_text, source_tag, desired_results=3):
    if not collection:
        return ["(Error de conexi√≥n a BD - Sin contexto disponible)"]
    
    try:
        RAW_FETCH_LIMIT = 15 
        query_emb = embedding_model.encode([query_text]).tolist()
        results = collection.query(
            query_embeddings=query_emb,
            n_results=RAW_FETCH_LIMIT, 
            where={"source": source_tag}
        )
        raw_docs = results['documents'][0] if results['documents'] else []
        
        unique_docs = []
        seen_content = set()
        
        for doc in raw_docs:
            clean_doc = doc.strip()
            if clean_doc not in seen_content:
                unique_docs.append(clean_doc)
                seen_content.add(clean_doc)
            if len(unique_docs) >= desired_results:
                break
        return unique_docs

    except Exception as e:
        return [f"(Error consultando Chroma: {str(e)})"]

def run_agent_process(agent_name, state: AgentState):
    question = state["question"]
    config = AGENTS_CONFIG[agent_name]
    
    search_query = f"{question} {config.get('keywords', '')}"
    print(f"   üîç {agent_name} buscando: '{search_query[:50]}...'")
    
    context_docs = query_chroma(search_query, config["source_filter"], desired_results=3)
    context_str = "\n".join([f"> {doc}" for doc in context_docs])
    
    template = """
    SYSTEM IDENTITY:
    Nombre: {agent_name}
    Rol: {role}
    Estilo: {style}
    
    DATOS RECUPERADOS:
    {context}
    
    PREGUNTA: "{query}"
    
    INSTRUCCIONES:
    1. Responde desde tu personaje.
    2. Usa los datos recuperados.
    
    RESTRICCIONES DE FORMATO (CR√çTICO):
    - NO uses t√≠tulos, NO escribas "Pensamiento Interno:", NO uses par√©ntesis introductorios.
    - Empieza a escribir tu idea directamente.
    - LONGITUD M√ÅXIMA: 80 PALABRAS o 5 ORACIONES.
    - S√â CONCISO.
    
    OUTPUT:
    √önicamente el contenido del pensamiento.
    """
    
    prompt = PromptTemplate.from_template(template)
    chain = prompt | llm
    
    try:
        response = chain.invoke({
            "agent_name": agent_name,
            "role": config["role"],
            "style": config["style"],
            "context": context_str,
            "query": question
        })
        thought = response.content
        
        # --- LIMPIEZA DE SEGURIDAD ---
        # Si el LLM desobedece y pone "Pensamiento Interno:", lo borramos aqu√≠.
        # Esto asegura que el frontend no tenga t√≠tulos duplicados.
        patterns_to_remove = [
            r"^Pensamiento Interno:\s*", 
            r"^\(Pensamiento Interno\)\s*",
            r"^Pensamiento:\s*",
            r"^Opini[o√≥]n:\s*"
        ]
        for pattern in patterns_to_remove:
            thought = re.sub(pattern, "", thought, flags=re.IGNORECASE).strip()

    except Exception as e:
        thought = f"[ERROR DE PROCESAMIENTO]: {str(e)}"
        
    return {
        "analysis_logs": [{
            "agent": agent_name,
            "thought": thought,
            "context_used": context_docs
        }]
    }

# --- 5. NODOS DEL GRAFO ---

def node_survivor(state: AgentState):
    return run_agent_process("Survivor", state)

def node_speculator(state: AgentState):
    return run_agent_process("Speculator", state)

def node_auteur(state: AgentState):
    return run_agent_process("Auteur", state)

def node_synthesizer(state: AgentState):
    print("   ‚öñÔ∏è  Sintetizando resultados...")
    logs = state["analysis_logs"]
    question = state["question"]
    
    logs_text = "\n\n".join([
        f"AGENTE {log['agent']}: {log['thought']}" 
        for log in logs
    ])
    
    template = """
    Eres 'The Historian'. Sintetiza los pensamientos de tres agentes ante: "{query}"
    
    INPUT:
    {logs}
    
    INSTRUCCIONES:
    Genera una 'S√≠ntesis Narrativa' breve (m√°x 120 palabras).
    Contrasta el miedo (Survivor), la frialdad financiera (Speculator) y la melancol√≠a (Auteur).
    Concluye con una reflexi√≥n sobre la disonancia cognitiva social que sirva para un estudio academico.
    """
    
    prompt = PromptTemplate.from_template(template)
    chain = prompt | llm
    response = chain.invoke({"query": question, "logs": logs_text})
    
    # Limpieza tambi√©n para el Historiador
    synthesis_text = response.content.replace("S√≠ntesis Narrativa:", "").strip()
    
    return {"final_synthesis": synthesis_text}

# --- 6. CONSTRUCCI√ìN DEL GRAFO ---

workflow = StateGraph(AgentState)
workflow.add_node("Survivor", node_survivor)
workflow.add_node("Speculator", node_speculator)
workflow.add_node("Auteur", node_auteur)
workflow.add_node("Synthesizer", node_synthesizer)

workflow.set_entry_point("Survivor")
workflow.add_edge("Survivor", "Speculator")
workflow.add_edge("Speculator", "Auteur")
workflow.add_edge("Auteur", "Synthesizer")
workflow.add_edge("Synthesizer", END)

app_graph = workflow.compile()